{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec7cd872-516a-4dcd-aed5-f11cd8c46dc7",
   "metadata": {},
   "source": [
    "## Find similar content from MLOps.Community meetups based on search. \n",
    "\n",
    "For context, I wanted to do that for all MLOps.community Meetups worldwide but the API for Meetup.com isn't free, therefore I decided to only do it for the ones of Berlin, I had to manually copy the data as well as Meetup wants you to be logged in to access the details of a Meetup.\n",
    "\n",
    "I am using Milvus to perform a Similarity Search with the content of the MLOps.community meetups. \n",
    "\n",
    "I also use ChatGPT to summarise the content of the most similar meetups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ea0221-714d-454c-aa3e-45abf55fce18",
   "metadata": {},
   "source": [
    "### Install all Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "999b9aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using version \u001b[39;1m^2.3.7\u001b[39;22m for \u001b[36mpymilvus\u001b[39m\n",
      "Using version \u001b[39;1m^1.14.1\u001b[39;22m for \u001b[36mopenai\u001b[39m\n",
      "Using version \u001b[39;1m^1.0.1\u001b[39;22m for \u001b[36mpython-dotenv\u001b[39m\n",
      "Using version \u001b[39;1m^2.5.1\u001b[39;22m for \u001b[36msentence-transformers\u001b[39m\n",
      "\n",
      "\u001b[34mUpdating dependencies\u001b[39m\n",
      "\u001b[2K\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(3.9s)\u001b[39;22m\n",
      "\n",
      "\u001b[39;1mPackage operations\u001b[39;22m: \u001b[34m0\u001b[39m installs, \u001b[34m4\u001b[39m updates, \u001b[34m0\u001b[39m removals\n",
      "\n",
      "  \u001b[34;1m-\u001b[39;22m \u001b[39mUpdating \u001b[39m\u001b[36mfsspec\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m2024.2.0\u001b[39;22m\u001b[39m -> \u001b[39m\u001b[39;1m2024.3.1\u001b[39;22m\u001b[39m)\u001b[39m: \u001b[34mPending...\u001b[39m\n",
      "\u001b[1A\u001b[0J  \u001b[34;1m-\u001b[39;22m \u001b[39mUpdating \u001b[39m\u001b[36mfsspec\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m2024.2.0\u001b[39;22m\u001b[39m -> \u001b[39m\u001b[39;1m2024.3.1\u001b[39;22m\u001b[39m)\u001b[39m: \u001b[34mDownloading...\u001b[39m \u001b[39;1m0%\u001b[39;22m\n",
      "\u001b[1A\u001b[0J  \u001b[34;1m-\u001b[39;22m \u001b[39mUpdating \u001b[39m\u001b[36mfsspec\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m2024.2.0\u001b[39;22m\u001b[39m -> \u001b[39m\u001b[39;1m2024.3.1\u001b[39;22m\u001b[39m)\u001b[39m: \u001b[34mDownloading...\u001b[39m \u001b[39;1m100%\u001b[39;22m\n",
      "\u001b[1A\u001b[0J  \u001b[34;1m-\u001b[39;22m \u001b[39mUpdating \u001b[39m\u001b[36mfsspec\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m2024.2.0\u001b[39;22m\u001b[39m -> \u001b[39m\u001b[39;1m2024.3.1\u001b[39;22m\u001b[39m)\u001b[39m: \u001b[34mInstalling...\u001b[39m\n",
      "\u001b[1A\u001b[0J  \u001b[32;1m-\u001b[39;22m \u001b[39mUpdating \u001b[39m\u001b[36mfsspec\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m2024.2.0\u001b[39;22m\u001b[39m -> \u001b[39m\u001b[32m2024.3.1\u001b[39m\u001b[39m)\u001b[39m\n",
      "  \u001b[34;1m-\u001b[39;22m \u001b[39mUpdating \u001b[39m\u001b[36mpyarrow\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m15.0.1\u001b[39;22m\u001b[39m -> \u001b[39m\u001b[39;1m15.0.2\u001b[39;22m\u001b[39m)\u001b[39m: \u001b[34mPending...\u001b[39m\n",
      "  \u001b[34;1m-\u001b[39;22m \u001b[39mUpdating \u001b[39m\u001b[36msetuptools\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m69.1.0\u001b[39;22m\u001b[39m -> \u001b[39m\u001b[39;1m69.2.0\u001b[39;22m\u001b[39m)\u001b[39m: \u001b[34mPending...\u001b[39m\n",
      "\u001b[1A\u001b[0J  \u001b[34;1m-\u001b[39;22m \u001b[39mUpdating \u001b[39m\u001b[36msetuptools\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m69.1.0\u001b[39;22m\u001b[39m -> \u001b[39m\u001b[39;1m69.2.0\u001b[39;22m\u001b[39m)\u001b[39m: \u001b[34mDownloading...\u001b[39m \u001b[39;1m0%\u001b[39;22m\n",
      "\u001b[2A\u001b[0J  \u001b[34;1m-\u001b[39;22m \u001b[39mUpdating \u001b[39m\u001b[36msetuptools\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m69.1.0\u001b[39;22m\u001b[39m -> \u001b[39m\u001b[39;1m69.2.0\u001b[39;22m\u001b[39m)\u001b[39m: \u001b[34mDownloading...\u001b[39m \u001b[39;1m0%\u001b[39;22m\n",
      "\u001b[1A\u001b[0J  \u001b[34;1m-\u001b[39;22m \u001b[39mUpdating \u001b[39m\u001b[36mpyarrow\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m15.0.1\u001b[39;22m\u001b[39m -> \u001b[39m\u001b[39;1m15.0.2\u001b[39;22m\u001b[39m)\u001b[39m: \u001b[34mInstalling...\u001b[39m\n",
      "  \u001b[34;1m-\u001b[39;22m \u001b[39mUpdating \u001b[39m\u001b[36msetuptools\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m69.1.0\u001b[39;22m\u001b[39m -> \u001b[39m\u001b[39;1m69.2.0\u001b[39;22m\u001b[39m)\u001b[39m: \u001b[34mDownloading...\u001b[39m \u001b[39;1m0%\u001b[39;22m\n",
      "\u001b[1A\u001b[0J  \u001b[34;1m-\u001b[39;22m \u001b[39mUpdating \u001b[39m\u001b[36msetuptools\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m69.1.0\u001b[39;22m\u001b[39m -> \u001b[39m\u001b[39;1m69.2.0\u001b[39;22m\u001b[39m)\u001b[39m: \u001b[34mDownloading...\u001b[39m \u001b[39;1m100%\u001b[39;22m\n",
      "\u001b[1A\u001b[0J  \u001b[34;1m-\u001b[39;22m \u001b[39mUpdating \u001b[39m\u001b[36msetuptools\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m69.1.0\u001b[39;22m\u001b[39m -> \u001b[39m\u001b[39;1m69.2.0\u001b[39;22m\u001b[39m)\u001b[39m: \u001b[34mInstalling...\u001b[39m\n",
      "\u001b[2A\u001b[0J  \u001b[34;1m-\u001b[39;22m \u001b[39mUpdating \u001b[39m\u001b[36msetuptools\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m69.1.0\u001b[39;22m\u001b[39m -> \u001b[39m\u001b[39;1m69.2.0\u001b[39;22m\u001b[39m)\u001b[39m: \u001b[34mInstalling...\u001b[39m\n",
      "\u001b[1A\u001b[0J  \u001b[32;1m-\u001b[39;22m \u001b[39mUpdating \u001b[39m\u001b[36mpyarrow\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m15.0.1\u001b[39;22m\u001b[39m -> \u001b[39m\u001b[32m15.0.2\u001b[39m\u001b[39m)\u001b[39m\n",
      "  \u001b[34;1m-\u001b[39;22m \u001b[39mUpdating \u001b[39m\u001b[36msetuptools\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m69.1.0\u001b[39;22m\u001b[39m -> \u001b[39m\u001b[39;1m69.2.0\u001b[39;22m\u001b[39m)\u001b[39m: \u001b[34mInstalling...\u001b[39m\n",
      "\u001b[1A\u001b[0J  \u001b[32;1m-\u001b[39;22m \u001b[39mUpdating \u001b[39m\u001b[36msetuptools\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m69.1.0\u001b[39;22m\u001b[39m -> \u001b[39m\u001b[32m69.2.0\u001b[39m\u001b[39m)\u001b[39m\n",
      "  \u001b[34;1m-\u001b[39;22m \u001b[39mUpdating \u001b[39m\u001b[36mopenai\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m1.14.0\u001b[39;22m\u001b[39m -> \u001b[39m\u001b[39;1m1.14.1\u001b[39;22m\u001b[39m)\u001b[39m: \u001b[34mPending...\u001b[39m\n",
      "\u001b[1A\u001b[0J  \u001b[34;1m-\u001b[39;22m \u001b[39mUpdating \u001b[39m\u001b[36mopenai\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m1.14.0\u001b[39;22m\u001b[39m -> \u001b[39m\u001b[39;1m1.14.1\u001b[39;22m\u001b[39m)\u001b[39m: \u001b[34mDownloading...\u001b[39m \u001b[39;1m0%\u001b[39;22m\n",
      "\u001b[1A\u001b[0J  \u001b[34;1m-\u001b[39;22m \u001b[39mUpdating \u001b[39m\u001b[36mopenai\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m1.14.0\u001b[39;22m\u001b[39m -> \u001b[39m\u001b[39;1m1.14.1\u001b[39;22m\u001b[39m)\u001b[39m: \u001b[34mDownloading...\u001b[39m \u001b[39;1m100%\u001b[39;22m\n",
      "\u001b[1A\u001b[0J  \u001b[34;1m-\u001b[39;22m \u001b[39mUpdating \u001b[39m\u001b[36mopenai\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m1.14.0\u001b[39;22m\u001b[39m -> \u001b[39m\u001b[39;1m1.14.1\u001b[39;22m\u001b[39m)\u001b[39m: \u001b[34mInstalling...\u001b[39m\n",
      "\u001b[1A\u001b[0J  \u001b[32;1m-\u001b[39;22m \u001b[39mUpdating \u001b[39m\u001b[36mopenai\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m1.14.0\u001b[39;22m\u001b[39m -> \u001b[39m\u001b[32m1.14.1\u001b[39m\u001b[39m)\u001b[39m\n",
      "\n",
      "\u001b[34mWriting lock file\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "! poetry add milvus==2.2.14 pymilvus openai python-dotenv sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3888062e-bf77-418b-8a97-fe13ac7455fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: milvus==2.2.14 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (2.2.14)\n",
      "Requirement already satisfied: pymilvus in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (2.3.7)\n",
      "Requirement already satisfied: openai in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (1.14.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: requests in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: sentence-transformers in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (2.5.1)\n",
      "Collecting llama-index\n",
      "  Downloading llama_index-0.10.19-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: setuptools>=67 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from pymilvus) (69.1.0)\n",
      "Requirement already satisfied: grpcio<=1.60.0,>=1.49.1 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from pymilvus) (1.60.0)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from pymilvus) (5.26.0)\n",
      "Requirement already satisfied: environs<=9.5.0 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from pymilvus) (9.5.0)\n",
      "Requirement already satisfied: ujson>=2.0.0 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from pymilvus) (5.9.0)\n",
      "Requirement already satisfied: pandas>=1.2.4 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from pymilvus) (2.2.1)\n",
      "Requirement already satisfied: minio>=7.0.0 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from pymilvus) (7.2.5)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from pymilvus) (15.0.1)\n",
      "Requirement already satisfied: azure-storage-blob in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from pymilvus) (12.19.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from openai) (2.6.4)\n",
      "Requirement already satisfied: sniffio in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from sentence-transformers) (4.38.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: numpy in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from sentence-transformers) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from sentence-transformers) (0.21.4)\n",
      "Requirement already satisfied: Pillow in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from sentence-transformers) (10.2.0)\n",
      "Collecting llama-index-agent-openai<0.2.0,>=0.1.4 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.1.5-py3-none-any.whl.metadata (695 bytes)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_cli-0.1.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.19 (from llama-index)\n",
      "  Downloading llama_index_core-0.10.19-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.1.6-py3-none-any.whl.metadata (654 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.1.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
      "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.5 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.1.9-py3-none-any.whl.metadata (558 bytes)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.1.4-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Downloading llama_index_program_openai-0.1.4-py3-none-any.whl.metadata (766 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.1.11-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.1.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: marshmallow>=3.0.0 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from environs<=9.5.0->pymilvus) (3.21.1)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: filelock in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
      "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Downloading SQLAlchemy-2.0.28-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Downloading aiohttp-3.9.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llamaindex-py-client<0.2.0,>=0.1.13 (from llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Downloading llamaindex_py_client-0.1.13-py3-none-any.whl.metadata (762 bytes)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (3.2.1)\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting tenacity<9.0.0,>=8.2.0 (from llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Downloading tiktoken-0.6.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bs4<0.0.3,>=0.0.2 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting pymupdf<2.0.0,>=1.23.21 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading PyMuPDF-1.23.26-cp311-none-macosx_11_0_arm64.whl.metadata (3.4 kB)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading pypdf-4.1.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse<0.4.0,>=0.3.3 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading llama_parse-0.3.9-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: argon2-cffi in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from minio>=7.0.0->pymilvus) (23.1.0)\n",
      "Requirement already satisfied: pycryptodome in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from minio>=7.0.0->pymilvus) (3.20.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from pandas>=1.2.4->pymilvus) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from pandas>=1.2.4->pymilvus) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from pandas>=1.2.4->pymilvus) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "Requirement already satisfied: sympy in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: jinja2 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.28.0 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from azure-storage-blob->pymilvus) (1.30.1)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from azure-storage-blob->pymilvus) (42.0.5)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from azure-storage-blob->pymilvus) (0.6.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.3.0)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Downloading multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Downloading yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: six>=1.11.0 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob->pymilvus) (1.16.0)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from cryptography>=2.1.4->azure-storage-blob->pymilvus) (1.16.0)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting click (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting PyMuPDFb==1.23.22 (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading PyMuPDFb-1.23.22-py3-none-macosx_11_0_arm64.whl.metadata (1.4 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Downloading greenlet-3.0.3-cp311-cp311-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from argon2-cffi->minio>=7.0.0->pymilvus) (21.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob->pymilvus) (2.21)\n",
      "Downloading llama_index-0.10.19-py3-none-any.whl (5.6 kB)\n",
      "Downloading llama_index_agent_openai-0.1.5-py3-none-any.whl (12 kB)\n",
      "Downloading llama_index_cli-0.1.9-py3-none-any.whl (25 kB)\n",
      "Downloading llama_index_core-0.10.19-py3-none-any.whl (15.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_embeddings_openai-0.1.6-py3-none-any.whl (6.0 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.1.4-py3-none-any.whl (6.6 kB)\n",
      "Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_llms_openai-0.1.9-py3-none-any.whl (10.0 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.1.4-py3-none-any.whl (5.8 kB)\n",
      "Downloading llama_index_program_openai-0.1.4-py3-none-any.whl (4.1 kB)\n",
      "Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.1.11-py3-none-any.whl (36 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.1.3-py3-none-any.whl (2.5 kB)\n",
      "Downloading aiohttp-3.9.3-cp311-cp311-macosx_11_0_arm64.whl (387 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.7/387.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading llama_parse-0.3.9-py3-none-any.whl (6.8 kB)\n",
      "Downloading llamaindex_py_client-0.1.13-py3-none-any.whl (107 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyMuPDF-1.23.26-cp311-none-macosx_11_0_arm64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyMuPDFb-1.23.22-py3-none-macosx_11_0_arm64.whl (29.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.28-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading tiktoken-0.6.0-cp311-cp311-macosx_11_0_arm64.whl (949 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m949.8/949.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl (53 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.3-cp311-cp311-macosx_11_0_universal2.whl (271 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.7/271.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Downloading wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
      "Downloading yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl (81 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: striprtf, dirtyjson, wrapt, tenacity, SQLAlchemy, soupsieve, pypdf, PyMuPDFb, mypy-extensions, multidict, greenlet, frozenlist, click, attrs, yarl, typing-inspect, tiktoken, pymupdf, nltk, deprecated, beautifulsoup4, aiosignal, llamaindex-py-client, dataclasses-json, bs4, aiohttp, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "Successfully installed PyMuPDFb-1.23.22 SQLAlchemy-2.0.28 aiohttp-3.9.3 aiosignal-1.3.1 attrs-23.2.0 beautifulsoup4-4.12.3 bs4-0.0.2 click-8.1.7 dataclasses-json-0.6.4 deprecated-1.2.14 dirtyjson-1.0.8 frozenlist-1.4.1 greenlet-3.0.3 llama-index-0.10.19 llama-index-agent-openai-0.1.5 llama-index-cli-0.1.9 llama-index-core-0.10.19 llama-index-embeddings-openai-0.1.6 llama-index-indices-managed-llama-cloud-0.1.4 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.9 llama-index-multi-modal-llms-openai-0.1.4 llama-index-program-openai-0.1.4 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.11 llama-index-readers-llama-parse-0.1.3 llama-parse-0.3.9 llamaindex-py-client-0.1.13 multidict-6.0.5 mypy-extensions-1.0.0 nltk-3.8.1 pymupdf-1.23.26 pypdf-4.1.0 soupsieve-2.5 striprtf-0.0.26 tenacity-8.2.3 tiktoken-0.6.0 typing-inspect-0.9.0 wrapt-1.16.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "! pip install milvus==2.2.14 pymilvus openai python-dotenv sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33f1fcfe-3674-4246-894c-40db408094db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460f371d-58da-4efe-bfb8-7f5796225987",
   "metadata": {},
   "source": [
    "#### I encountered some problems with using `default_server` from Milvus so I am using the `debug_server`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdd11b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['default']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymilvus import connections, db\n",
    "from milvus import default_server\n",
    "\n",
    "conn = connections.connect(uri=f'http://localhost:{default_server.listen_port}')\n",
    "\n",
    "db.list_database()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4dbaf7-de73-40be-8840-602c5546dcdc",
   "metadata": {},
   "source": [
    "## Create the Milvus collection needed to perform a similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe67f3ee-518c-4867-a2da-49f0e43f21b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import utility\n",
    "\n",
    "if utility.has_collection(\"mlops_meetups_berlin\"):\n",
    "    utility.drop_collection(\"mlops_meetups_berlin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6479b480-25ed-45cf-afaa-85d24f3eff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import FieldSchema, CollectionSchema, DataType, Collection\n",
    "\n",
    "# object should be inserted in the format of title, date, content, content embedding\n",
    "fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name=\"title\", dtype=DataType.VARCHAR, max_length=500),\n",
    "    FieldSchema(name=\"date\", dtype=DataType.VARCHAR, max_length=100),\n",
    "    FieldSchema(name=\"content\", dtype=DataType.VARCHAR, max_length=10000),\n",
    "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=384)\n",
    "]\n",
    "schema = CollectionSchema(fields=fields)\n",
    "collection = Collection(name=\"mlops_meetups_berlin\", schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2db0a1fe-5ec4-4329-9159-5adb5be4b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.create_index(field_name=\"embedding\")\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e79ceac-2d7e-47fc-82f1-e20e362ac3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stephen/Library/Caches/pypoetry/virtualenvs/mlops-community-vector-search-DDGVbuBb-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "transformer = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f3b8c65-c81d-42b6-aa80-93ed6b456cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLOps.community Berlin Meetup 05</td>\n",
       "      <td>Thursday, September 14, 2023</td>\n",
       "      <td>Details\\nHello Community!\\n\\nGet your calendar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLOps.community Berlin 04: Pre-event Women+ In...</td>\n",
       "      <td>Thursday, June 29, 2023</td>\n",
       "      <td>Details\\nHello Community!\\n\\nGet your calendar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[In-person] Vector DB &amp; LLM Hackathon</td>\n",
       "      <td>Saturday, June 17, 2023</td>\n",
       "      <td>Details\\nJoin us on Saturday, June 17 in Berli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLOps.community Berlin Meetup 03</td>\n",
       "      <td>Thursday, February 2, 2023</td>\n",
       "      <td>Details\\nHello Community!\\n\\nOn February 2nd w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLOps.community Berlin Meetup 02</td>\n",
       "      <td>Thursday, October 6, 2022</td>\n",
       "      <td>Details\\nHello Community!\\n\\nOn October 6th we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                   MLOps.community Berlin Meetup 05   \n",
       "1  MLOps.community Berlin 04: Pre-event Women+ In...   \n",
       "2              [In-person] Vector DB & LLM Hackathon   \n",
       "3                   MLOps.community Berlin Meetup 03   \n",
       "4                   MLOps.community Berlin Meetup 02   \n",
       "\n",
       "                           date  \\\n",
       "0  Thursday, September 14, 2023   \n",
       "1       Thursday, June 29, 2023   \n",
       "2       Saturday, June 17, 2023   \n",
       "3    Thursday, February 2, 2023   \n",
       "4     Thursday, October 6, 2022   \n",
       "\n",
       "                                             content  \n",
       "0  Details\\nHello Community!\\n\\nGet your calendar...  \n",
       "1  Details\\nHello Community!\\n\\nGet your calendar...  \n",
       "2  Details\\nJoin us on Saturday, June 17 in Berli...  \n",
       "3  Details\\nHello Community!\\n\\nOn February 2nd w...  \n",
       "4  Details\\nHello Community!\\n\\nOn October 6th we...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('data/data_meetup.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b955034-d65e-4927-9d54-a9c5027d6697",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_detail = df['content']\n",
    "content_detail = content_detail.tolist()\n",
    "embeddings = [transformer.encode(c) for c in content_detail]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39ada90-6559-45b3-9c68-424aa5b5789b",
   "metadata": {},
   "source": [
    "#### Embed the content to be able to search it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de8fee9b-0ee6-4fbe-bb01-15a3369b9e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLOps.community Berlin Meetup 05</td>\n",
       "      <td>Thursday, September 14, 2023</td>\n",
       "      <td>Details\\nHello Community!\\n\\nGet your calendar...</td>\n",
       "      <td>[-0.12466437, -0.050888978, -0.011999283, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLOps.community Berlin 04: Pre-event Women+ In...</td>\n",
       "      <td>Thursday, June 29, 2023</td>\n",
       "      <td>Details\\nHello Community!\\n\\nGet your calendar...</td>\n",
       "      <td>[-0.0037062387, -0.04097239, 0.040712878, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[In-person] Vector DB &amp; LLM Hackathon</td>\n",
       "      <td>Saturday, June 17, 2023</td>\n",
       "      <td>Details\\nJoin us on Saturday, June 17 in Berli...</td>\n",
       "      <td>[-0.036718927, -0.07346592, 0.009544252, 0.016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLOps.community Berlin Meetup 03</td>\n",
       "      <td>Thursday, February 2, 2023</td>\n",
       "      <td>Details\\nHello Community!\\n\\nOn February 2nd w...</td>\n",
       "      <td>[-0.03421999, -0.063562274, -0.011161464, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLOps.community Berlin Meetup 02</td>\n",
       "      <td>Thursday, October 6, 2022</td>\n",
       "      <td>Details\\nHello Community!\\n\\nOn October 6th we...</td>\n",
       "      <td>[-0.014285266, -0.08103279, -0.023105947, 0.06...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                   MLOps.community Berlin Meetup 05   \n",
       "1  MLOps.community Berlin 04: Pre-event Women+ In...   \n",
       "2              [In-person] Vector DB & LLM Hackathon   \n",
       "3                   MLOps.community Berlin Meetup 03   \n",
       "4                   MLOps.community Berlin Meetup 02   \n",
       "\n",
       "                           date  \\\n",
       "0  Thursday, September 14, 2023   \n",
       "1       Thursday, June 29, 2023   \n",
       "2       Saturday, June 17, 2023   \n",
       "3    Thursday, February 2, 2023   \n",
       "4     Thursday, October 6, 2022   \n",
       "\n",
       "                                             content  \\\n",
       "0  Details\\nHello Community!\\n\\nGet your calendar...   \n",
       "1  Details\\nHello Community!\\n\\nGet your calendar...   \n",
       "2  Details\\nJoin us on Saturday, June 17 in Berli...   \n",
       "3  Details\\nHello Community!\\n\\nOn February 2nd w...   \n",
       "4  Details\\nHello Community!\\n\\nOn October 6th we...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.12466437, -0.050888978, -0.011999283, 0.07...  \n",
       "1  [-0.0037062387, -0.04097239, 0.040712878, 0.04...  \n",
       "2  [-0.036718927, -0.07346592, 0.009544252, 0.016...  \n",
       "3  [-0.03421999, -0.063562274, -0.011161464, -0.0...  \n",
       "4  [-0.014285266, -0.08103279, -0.023105947, 0.06...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['embedding'] = embeddings\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9c52287-e21e-4f6f-913b-0c44b5b6a500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(insert count: 6, delete count: 0, upsert count: 0, timestamp: 448470526131961858, success count: 6, err count: 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.insert(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63a09641-8f48-4757-8d90-ef0419619e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = \"The speaker speaks about Open Source and ML Platform\"\n",
    "search_data = [transformer.encode(search_terms)] # Must be a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b2c5967-ea09-4a26-b1a9-7ff720baf96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = collection.search(\n",
    "    data=search_data,  # Embedded search value\n",
    "    anns_field=\"embedding\",  # Search across embeddings\n",
    "    param={\"metric_type\": \"IP\"},\n",
    "    limit = 3,  # Limit to top_k results per search\n",
    "    output_fields=[\"title\", \"content\"]  # Include title field in result\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7eb66ae-8d46-4c43-b9c2-7fb9b8c9f4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_meetup_content(content: str) -> str: \n",
    "    response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": \"Summarize content you are provided with.\"\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": f\"{content}\"\n",
    "        }\n",
    "    ],\n",
    "        temperature=0,\n",
    "        max_tokens=1024,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    summary = response.choices[0].message.content\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "947c2035-9b58-4c68-8d1a-11d2f449c72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Terms: The speaker speaks about Open Source and ML Platform\n",
      "Results:\n",
      "First MLOps.community Berlin Meetup ---- 0.5537543296813965\n",
      "The MLOps.community meetup in Berlin on June 30th will feature a main talk by Stephen Batifol from Wolt on Scaling Open-Source Machine Learning. The event will also include lightning talks, networking, and food/drinks. The agenda includes Stephen's talk, Q&A session, lightning talks, and socializing. Attendees can sign up for lightning talks on Meetup.com. The event is in collaboration with neptune.ai. \n",
      "\n",
      "MLOps.community Berlin 04: Pre-event Women+ In Data and AI Festival ---- 0.46235063672065735\n",
      "The MLOps.community Berlin is hosting a special edition event on June 29th and 30th at Thoughtworks. This event serves as a warm-up for the Women+ In Data and AI festival. The meetup will feature speakers Fiona Coath discussing surveillance capitalism and Magdalena Stenius talking about the carbon footprint of machine learning. The agenda includes talks, lightning talks, and networking opportunities. Attendees are encouraged to review and adhere to the event's Code of Conduct for an inclusive and respectful environment. \n",
      "\n",
      "MLOps.community Berlin Meetup 02 ---- 0.41342613101005554\n",
      "The MLOps.community meetup in Berlin on October 6th will feature a main talk by Lina Weichbrodt on ML Monitoring, along with lightning talks and networking opportunities. The event will be held at Wolt's office with a capacity limit of 150 people. Lina has extensive experience in developing scalable machine learning models and has worked at companies like Zalando and DKB. The agenda includes a bonding activity, main talk, lightning talks, and socializing time. Attendees can also sign up for lightning talks on various topics related to MLOps. The event is in collaboration with neptune.ai. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for hits_i, hits in enumerate(res):\n",
    "    print(\"Search Terms:\", search_terms)\n",
    "    print(\"Results:\")\n",
    "    for hit in hits:\n",
    "        content_test = hit.entity.get(\"content\")\n",
    "        print(hit.entity.get(\"title\"), \"----\", hit.distance)\n",
    "        print(f'{summarise_meetup_content(hit.entity.get(\"content\"))} \\n')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
